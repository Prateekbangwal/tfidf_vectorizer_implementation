{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MR-gIIIdvGJ"
   },
   "source": [
    "#TF-IDF IMPLEMENTATION\n",
    "\n",
    "##SKLEARN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2wxGfOqhfGRl"
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XZj_0SwSdoaH"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l4Kni5JseweZ"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "skl_output = vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "XuttH4nxfXXV",
    "outputId": "8bf4201a-aff5-46e2-e7ec-75fb2b0006b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "# sklearn feature names, they are sorted in alphabetic order by default.\n",
    "\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "g0nEd3tMfbf3",
    "outputId": "dc83ad45-3cbc-4e4d-efdf-4104a152ab26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Here we will print the sklearn tfidf vectorizer idf values after applying the fit method\n",
    "# After using the fit function on the corpus the vocab has 9 words in it, and each has its idf value.\n",
    "\n",
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Ez_2fJe0ff05",
    "outputId": "fe78bdb9-453c-4116-cd70-2e01752190dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of sklearn tfidf vectorizer output after applying transform method.\n",
    "\n",
    "skl_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "R75qY16Pfi4h",
    "outputId": "46376ced-671d-4cf1-e1ca-07af7f2687ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.38408524091481483\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 1)\t0.46979138557992045\n"
     ]
    }
   ],
   "source": [
    "# sklearn tfidf values for first line of the above corpus.\n",
    "# Here the output is a sparse matrix\n",
    "\n",
    "print(skl_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "3tfHPEKJflRE",
    "outputId": "fcab1245-e7b5-468b-97fb-58b9624682cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn tfidf values for first line of the above corpus.\n",
    "# To understand the output better, here we are converting the sparse output matrix to dense matrix and printing it.\n",
    "# Notice that this output is normalized using L2 normalization. sklearn does this by default.\n",
    "\n",
    "print(skl_output[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzoENprLfpwe"
   },
   "source": [
    "##CUSTOM IMPLEMENTATION##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWOOLi9Pl7Rb"
   },
   "source": [
    "###IDF Function ###\n",
    "parameters : corpus: set of documents; unique_words : list of sorted unique words\n",
    "\n",
    "output : dictionary with word as key and its idf value as value\n",
    "\n",
    "\n",
    "IDF formula :  $IDF(t) = 1+\\log_{e}\\frac{1\\text{ }+\\text{ Total  number of documents in collection}} {1+\\text{Number of documents with term t in it}}.$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W8j10B4pgeFY"
   },
   "outputs": [],
   "source": [
    "def idf(corpus,unique_words):\n",
    "  idf_dict = {}\n",
    "  total_number_of_documents_in_collection = len(corpus)\n",
    "  for word in unique_words:\n",
    "    count = 0\n",
    "    for sentence in corpus:\n",
    "      if word in sentence.split(\" \"):\n",
    "        count +=1\n",
    "      idf_dict[word]=(math.log((1+total_number_of_documents_in_collection)/(count+1)))+1\n",
    "  return idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMrCMgOlmY59"
   },
   "source": [
    "###FIT Function ###\n",
    "parameters : corpus : set of documents\n",
    "\n",
    "outputs : vocab: vocabulary dictionary; idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VFnEWPOmfnxe"
   },
   "outputs": [],
   "source": [
    "def fit(corpus):\n",
    "  unique_words = set()\n",
    "  if isinstance(corpus, (list,)):\n",
    "    for row in corpus:\n",
    "      for word in row.split(\" \"):\n",
    "        if len(word) < 2:\n",
    "          continue\n",
    "        unique_words.add(word)\n",
    "    unique_words = sorted(list(unique_words))\n",
    "    vocab = {j:i for i, j in enumerate(unique_words)}\n",
    "    idf_dict = idf(corpus, unique_words)\n",
    "    return vocab, idf_dict\n",
    "  else:\n",
    "    print('Please Pass the list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KoQsiXajgmXg"
   },
   "outputs": [],
   "source": [
    "vocab, idf_dict = fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "BcIhjgbxg2t_",
    "outputId": "0704bce4-fa1c-4bdf-fed5-7b0742030e80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(list(vocab.keys()))\n",
    "print(list(idf_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAd1J5TLm2KO"
   },
   "source": [
    "###Transform function###\n",
    "parameters : corpus: set of documents, \n",
    "             vocab : vocabulary, \n",
    "             idf_dict\n",
    "\n",
    "outputs : normalised sparse matrix\n",
    "\n",
    "Using L2 Normalisation : document - https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dsZ4hMKog_dJ"
   },
   "outputs": [],
   "source": [
    "def transform(corpus, vocab, idf_dict):\n",
    "  rows = []\n",
    "  columns = []\n",
    "  values = []\n",
    "  if isinstance(corpus, (list,)):\n",
    "    for idx, string in enumerate(corpus):\n",
    "      no_of_terms_in_document = len(string.split(\" \"))\n",
    "      for word in string.split(\" \"):\n",
    "        if word in list(vocab.keys()):\n",
    "          no_of_times_word_in_string = string.split(\" \").count(word)\n",
    "          tf_idf_values = (no_of_times_word_in_string / no_of_terms_in_document) * idf_dict[word]\n",
    "          col_index = vocab.get(word, -1)\n",
    "          if col_index != -1:\n",
    "            rows.append(idx)\n",
    "            columns.append(col_index)\n",
    "            values.append(tf_idf_values)\n",
    "    output_matrix = csr_matrix((values, (rows,columns)), shape=(len(corpus),len(vocab)))\n",
    "    output_norm_matrix = normalize(output_matrix, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "    return output_norm_matrix\n",
    "  else:\n",
    "    print(\"Please Pass the list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Mw_GiyzFhORc"
   },
   "outputs": [],
   "source": [
    "csr_norm_matrix = transform(corpus, vocab, idf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ceeG7KgDhRD6",
    "outputId": "03c7f2d5-bc59-462e-8f4b-3ff36789c3f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "# Shape of normalised matrix aftee transform matrix\n",
    "print(csr_norm_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhCWM5DohnjG"
   },
   "source": [
    "###Shape of sklearn implementation and Custom implementation matrices are same i.e (4,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "YXe_Z-wXhezJ",
    "outputId": "17953413-1acd-4617-d9f1-60805ebd556b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.4697913855799205\n",
      "  (0, 2)\t0.580285823684436\n",
      "  (0, 3)\t0.3840852409148149\n",
      "  (0, 6)\t0.3840852409148149\n",
      "  (0, 8)\t0.3840852409148149\n"
     ]
    }
   ],
   "source": [
    "print(csr_norm_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrWli6xniiQ6"
   },
   "source": [
    "### For Reference###\n",
    "\n",
    "1st Matrix of Sklearn implementation\n",
    "\n",
    "  (0, 8)\t0.38408524091481483\n",
    "\n",
    "  (0, 6)\t0.38408524091481483\n",
    "\n",
    "  (0, 3)\t0.38408524091481483\n",
    "\n",
    "  (0, 2)\t0.5802858236844359\n",
    "  \n",
    "  (0, 1)\t0.46979138557992045\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVlfZz28nok5"
   },
   "source": [
    "#TASK-2#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "973FWeBEl3tR",
    "outputId": "70d91503-a6e0-4fbd-c41d-e5ef1a1031ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in corpus =  746\n"
     ]
    }
   ],
   "source": [
    "# Below is the code to load the cleaned_strings pickle file provided\n",
    "# Here corpus is of list type\n",
    "\n",
    "import pickle\n",
    "with open('cleaned_strings', 'rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "    \n",
    "# printing the length of the corpus loaded\n",
    "print(\"Number of documents in corpus = \",len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiwzQ6z61rLc"
   },
   "source": [
    "Here in fit function i am taking top 50 idf values from idf dict into my vocab\n",
    "\n",
    "Refernce: Taking top N values in sorted order from dictionary : https://www.geeksforgeeks.org/python-n-largest-values-in-dictionary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KwpYlhy4-Clq"
   },
   "outputs": [],
   "source": [
    "import itertools \n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "def fit_2(corpus):\n",
    "  unique_words = set()\n",
    "  if isinstance(corpus, (list,)):\n",
    "    for row in corpus:\n",
    "      for word in row.split(\" \"):\n",
    "        if len(word) < 2:\n",
    "          continue\n",
    "        unique_words.add(word)\n",
    "    unique_words = sorted(list(unique_words))\n",
    "    idf_dict = idf(corpus, unique_words)\n",
    "    vocab = dict(sorted(idf_dict.items(), key = itemgetter(1), reverse = True)[:50])\n",
    "    return vocab, idf_dict\n",
    "  else:\n",
    "    print('Please Pass the list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LNLOXpN5-Iz6"
   },
   "outputs": [],
   "source": [
    "vocab, idf_dict= fit_2(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2ZoVuzLK-LTU",
    "outputId": "50959cc0-543d-4a4d-bf3f-e7972faf9910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "usHgCW4S-OUy"
   },
   "outputs": [],
   "source": [
    "def transform_2(corpus, vocab, idf_dict):\n",
    "  rows = []\n",
    "  columns = []\n",
    "  values = []\n",
    "  if isinstance(corpus, (list,)):\n",
    "    for idx, string in enumerate(corpus):\n",
    "      no_of_terms_in_document = len(string.split(\" \"))\n",
    "      for word in string.split(\" \"):\n",
    "        if word in list(vocab.keys()):\n",
    "          no_of_times_word_in_string = string.split(\" \").count(word)\n",
    "          tf_idf_values = (no_of_times_word_in_string / no_of_terms_in_document) * idf_dict[word]\n",
    "          col_index = vocab.get(word, -1)\n",
    "          if col_index != -1:\n",
    "            rows.append(idx)\n",
    "            columns.append(col_index)\n",
    "            values.append(tf_idf_values)\n",
    "    output_matrix = csr_matrix((values, (rows,columns)), shape=(len(corpus),len(vocab)))\n",
    "    output_norm_matrix = normalize(output_matrix, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "    return output_norm_matrix\n",
    "  else:\n",
    "    print(\"Please pass the list as argument\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "pbRNaCNt-QqY",
    "outputId": "e077d3fc-b0c0-41c4-a24b-c7b162aa3ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(746, 50)\n"
     ]
    }
   ],
   "source": [
    "csr_norm_matrix = transform_2(corpus, vocab, idf_dict)\n",
    "print(csr_norm_matrix.shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TF_IDF_CUSTOM_SKLEARN_IMPLEMENTATION.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
